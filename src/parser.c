/*

This file was generated by the "C - Kessels engine template.c" template.

*/

#include "parser.h"
#include "grammar.h"                /* Generated by GOLD. */



/***** Helper subroutines ***************************************************/




/* Make a readable copy of a string. All characters outside 32...127 are
   displayed as a HEX number in square brackets, for example "[0A]". */
void ReadableString(wchar_t *Input, wchar_t *Output, long Width) {
  char s1[BUFSIZ];
  long i1;
  long i2;

  /* Sanity check. */
  if ((Output == NULL) || (Width < 1)) return;
  Output[0] = 0;
  if (Input == NULL) return;

  i1 = 0;
  i2 = 0;
  while ((i2 < Width - 1) && (Input[i1] != 0)) {
    if ((Input[i1] >= 32) && (Input[i1] <= 127)) {
        Output[i2++] = Input[i1];
      } else {
        if (Width - i2 > 4) {
          sprintf(s1,"%02X",Input[i1]);
          Output[i2++] = '[';
          Output[i2++] = s1[0];
          Output[i2++] = s1[1];
          Output[i2++] = ']';
          }
        }
    i1++;
    }
  Output[i2] = 0;
  }




void ShowIndent(int Indent) {
  int i;
  for (i = 0; i < Indent; i++) fprintf(stdout,"  ");
  }




/***** Rule subroutine template *********************************************/




/* This subroutine is a template of things that can happen in the
   subroutine of a rule. It shows how to access the value of symbols
   and how to call rules, and how to transport results and stuff via
   the Context.

   For example the rule:

     <Increment> ::= <Expression> '+' Number

   Has 3 sub-tokens:

     Token->Tokens[0] = token for <Expression>, a rule
     Token->Tokens[1] = token for '+', a symbol
     Token->Tokens[2] = token for Number, a symbol

   We know Token->Tokens[0] is a rule, because that's what the grammar
   says. We may assume that the engine has fully populated the sub-tokens
   and don't have to perform any checks. We can immediately call the
   subroutine of the rule, like this:

     RuleJumpTable[Token->Tokens[0]->ReductionRule](Token->Tokens[0],Context);

   The subroutine should hand back it's results via the Context. Here
   is an example of how to store a result in the context:

     Context->ReturnValue = (wchar_t *)wcsdup(....);

   Symbols are literal strings from the input (that was parsed by the
   engine), stored in the sub-token. We can get the value of the "Number"
   symbol like this:

     Value = (wchar_t *)wcsdup(Token->Tokens[2]->Data);

   Further reading:
   - See "engine.h" for the definition of the TokenStruct.
   - See "readme.txt" for a short discussion on how to use the content
     of a Token.
   - See "example4.c" for a working template example.
   */

void RuleTemplate(struct TokenStruct *Token, struct ContextStruct *Context) {
  int i;

  /* Debugging: show the description of the rule. */
  if (Context->Debug > 0) {
    ShowIndent(Context->Indent);
    fprintf(stdout,"Executing rule: %ls\n",Grammar.RuleArray[Token->ReductionRule].Description);
    }

  /* For all the sub-Tokens. */
  for (i = 0; i < Grammar.RuleArray[Token->ReductionRule].SymbolsCount; i++) {
    /* See if the Token is a Symbol or a Rule. */
    if (Token->Tokens[i]->ReductionRule < 0) {
        /* It's a Symbol. Make a copy of the Data. Most symbols are grammar,
           for example '+', 'function', 'while', and such, and you won't
           need to look at the Data. Other symbols are literals from the input
           script, for example numbers, strings, variable names, and such. */
        if (Context->ReturnValue != NULL) free(Context->ReturnValue);
        Context->ReturnValue = (wchar_t *)wcsdup(Token->Tokens[i]->Data);

        /* Debugging: show a description of the Symbol, and it's value. */
        if (Context->Debug > 0) {
          ShowIndent(Context->Indent + 1);
          fprintf(stdout,"Token[%u] = Symbol('%ls') = '%ls'\n",i,
            Grammar.SymbolArray[Token->Tokens[i]->Symbol].Name,
            Context->ReturnValue);
          }

      } else {
        /* It's a rule. */

        /* Debugging: show a description of the rule. */
        if (Context->Debug > 0) {
          ShowIndent(Context->Indent + 1);
          fprintf(stdout,"Token[%u] = Rule = %ls\n",i,
            Grammar.RuleArray[Token->Tokens[i]->ReductionRule].Description);
          }

        /* Call the rule's subroutine via the RuleJumpTable. */
        Context->Indent = Context->Indent + 1;
        RuleJumpTable[Token->Tokens[i]->ReductionRule](Token->Tokens[i],Context);
        Context->Indent = Context->Indent - 1;

        /* At this point you will probably want to save the Context->ReturnValue
           somewhere. */

        /* Debugging: show the value that was returned by the rule's subroutine. */
        if (Context->Debug > 0) {
          ShowIndent(Context->Indent + 2);
          fprintf(stdout,"Result value = %ls\n",Context->ReturnValue);
          }
        }
    }

  /* Do whatever processing is needed by the rule. Remember to free() the
     Values you have saved. */
  }




/***** Rule subroutines *****************************************************/




/* <Program> ::= <StatementList> */
void Rule_Program(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <StatementList> ::= <Statement> <StatementList> */
void Rule_StatementList(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <StatementList> ::= <Return> */
void Rule_StatementList2(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Statement> ::= <Declaration> */
void Rule_Statement(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Statement> ::= <Assignment> */
void Rule_Statement2(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Statement> ::= <Step> */
void Rule_Statement3(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Declaration> ::= Identifier was a <Type> <Separator> */
void Rule_Declaration_Identifier_was_a(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Declaration> ::= Identifier was a <Type> too <Separator> */
void Rule_Declaration_Identifier_was_a_too(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Assignment> ::= Identifier became <Terminal> <Separator> */
void Rule_Assignment_Identifier_became(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Step> ::= Identifier ate <Separator> */
void Rule_Step_Identifier_ate(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Step> ::= Identifier drank <Separator> */
void Rule_Step_Identifier_drank(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Terminal> ::= <Expr> */
void Rule_Terminal(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Terminal> ::= Character */
void Rule_Terminal_Character(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Separator> ::= and */
void Rule_Separator_and(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Separator> ::= but */
void Rule_Separator_but(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Separator> ::= then */
void Rule_Separator_then(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Separator> ::= ',' */
void Rule_Separator_Comma(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Separator> ::= '.' */
void Rule_Separator_Dot(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Type> ::= number */
void Rule_Type_number(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Type> ::= letter */
void Rule_Type_letter(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Return> ::= Alice found <Terminal> '.' */
void Rule_Return_Alice_found_Dot(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Expr> ::= <Expr> '|' <Xors> */
void Rule_Expr_Pipe(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Expr> ::= <Xors> */
void Rule_Expr(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Xors> ::= <Xors> '^' <Ands> */
void Rule_Xors_Caret(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Xors> ::= <Ands> */
void Rule_Xors(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Ands> ::= <Ands> '&' <Sums> */
void Rule_Ands_Amp(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Ands> ::= <Sums> */
void Rule_Ands(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Sums> ::= <Sums> <Plus> <Trms> */
void Rule_Sums(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Sums> ::= <Trms> */
void Rule_Sums2(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Trms> ::= <Trms> <Mult> <Nots> */
void Rule_Trms(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Trms> ::= <Nots> */
void Rule_Trms2(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Nots> ::= '~' <Nots> */
void Rule_Nots_Tilde(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Nots> ::= <Fact> */
void Rule_Nots(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Fact> ::= Identifier */
void Rule_Fact_Identifier(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Fact> ::= Constant */
void Rule_Fact_Constant(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Plus> ::= '+' */
void Rule_Plus_Plus(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Plus> ::= '-' */
void Rule_Plus_Minus(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Mult> ::= '*' */
void Rule_Mult_Times(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Mult> ::= '/' */
void Rule_Mult_Div(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/* <Mult> ::= '%' */
void Rule_Mult_Percent(struct TokenStruct *Token, struct ContextStruct *Context) {
  RuleTemplate(Token,Context);
  };




/***** Rule jumptable *******************************************************/




void (*RuleJumpTable[])(struct TokenStruct *Token, struct ContextStruct *Context) = {

  /* 0. <Program> ::= <StatementList> */
  Rule_Program,

  /* 1. <StatementList> ::= <Statement> <StatementList> */
  Rule_StatementList,

  /* 2. <StatementList> ::= <Return> */
  Rule_StatementList2,

  /* 3. <Statement> ::= <Declaration> */
  Rule_Statement,

  /* 4. <Statement> ::= <Assignment> */
  Rule_Statement2,

  /* 5. <Statement> ::= <Step> */
  Rule_Statement3,

  /* 6. <Declaration> ::= Identifier was a <Type> <Separator> */
  Rule_Declaration_Identifier_was_a,

  /* 7. <Declaration> ::= Identifier was a <Type> too <Separator> */
  Rule_Declaration_Identifier_was_a_too,

  /* 8. <Assignment> ::= Identifier became <Terminal> <Separator> */
  Rule_Assignment_Identifier_became,

  /* 9. <Step> ::= Identifier ate <Separator> */
  Rule_Step_Identifier_ate,

  /* 10. <Step> ::= Identifier drank <Separator> */
  Rule_Step_Identifier_drank,

  /* 11. <Terminal> ::= <Expr> */
  Rule_Terminal,

  /* 12. <Terminal> ::= Character */
  Rule_Terminal_Character,

  /* 13. <Separator> ::= and */
  Rule_Separator_and,

  /* 14. <Separator> ::= but */
  Rule_Separator_but,

  /* 15. <Separator> ::= then */
  Rule_Separator_then,

  /* 16. <Separator> ::= ',' */
  Rule_Separator_Comma,

  /* 17. <Separator> ::= '.' */
  Rule_Separator_Dot,

  /* 18. <Type> ::= number */
  Rule_Type_number,

  /* 19. <Type> ::= letter */
  Rule_Type_letter,

  /* 20. <Return> ::= Alice found <Terminal> '.' */
  Rule_Return_Alice_found_Dot,

  /* 21. <Expr> ::= <Expr> '|' <Xors> */
  Rule_Expr_Pipe,

  /* 22. <Expr> ::= <Xors> */
  Rule_Expr,

  /* 23. <Xors> ::= <Xors> '^' <Ands> */
  Rule_Xors_Caret,

  /* 24. <Xors> ::= <Ands> */
  Rule_Xors,

  /* 25. <Ands> ::= <Ands> '&' <Sums> */
  Rule_Ands_Amp,

  /* 26. <Ands> ::= <Sums> */
  Rule_Ands,

  /* 27. <Sums> ::= <Sums> <Plus> <Trms> */
  Rule_Sums,

  /* 28. <Sums> ::= <Trms> */
  Rule_Sums2,

  /* 29. <Trms> ::= <Trms> <Mult> <Nots> */
  Rule_Trms,

  /* 30. <Trms> ::= <Nots> */
  Rule_Trms2,

  /* 31. <Nots> ::= '~' <Nots> */
  Rule_Nots_Tilde,

  /* 32. <Nots> ::= <Fact> */
  Rule_Nots,

  /* 33. <Fact> ::= Identifier */
  Rule_Fact_Identifier,

  /* 34. <Fact> ::= Constant */
  Rule_Fact_Constant,

  /* 35. <Plus> ::= '+' */
  Rule_Plus_Plus,

  /* 36. <Plus> ::= '-' */
  Rule_Plus_Minus,

  /* 37. <Mult> ::= '*' */
  Rule_Mult_Times,

  /* 38. <Mult> ::= '/' */
  Rule_Mult_Div,

  /* 39. <Mult> ::= '%' */
  Rule_Mult_Percent 
  };




/***** Main *****************************************************************/




/* Load input file from disk into memory. */
wchar_t *LoadInputFile(char *FileName) {
  FILE *Fin;
  char *Buf1;
  wchar_t *Buf2;
  struct stat statbuf;
  size_t BytesRead;
  unsigned long i;

  /* Sanity check. */
  if ((FileName == NULL) || (*FileName == '\0')) return(NULL);

  /* Open the file. */
  Fin = fopen(FileName,"rb");
  if (Fin == NULL) {
    fprintf(stdout,"Could not open input file: %s\n",FileName);
    return(NULL);
    }

  /* Get the size of the file. */
  if (fstat(fileno(Fin),&statbuf) != 0) {
    fprintf(stdout,"Could not stat() the input file: %s\n",FileName);
    fclose(Fin);
    return(NULL);
    }

  /* Allocate memory for the input. */
  Buf1 = (char *)malloc(statbuf.st_size + 1);
  Buf2 = (wchar_t *)malloc(sizeof(wchar_t) * (statbuf.st_size + 1));
  if ((Buf1 == NULL) || (Buf2 == NULL)) {
    fprintf(stdout,"Not enough memory to load the file: %s\n",FileName);
    fclose(Fin);
    if (Buf1 != NULL) free(Buf1);
    if (Buf2 != NULL) free(Buf2);
    return(NULL);
    }

  /* Load the file into memory. */
  BytesRead = fread(Buf1,1,statbuf.st_size,Fin);
  Buf1[BytesRead] = '\0';

  /* Close the file. */
  fclose(Fin);

  /* Exit if there was an error while reading the file. */
  if (BytesRead != statbuf.st_size) {
    fprintf(stdout,"Error while reading input file: %s\n",FileName);
    free(Buf1);
    free(Buf2);
    return(NULL);
    }

  /* Convert from ASCII to Unicode. */
  for (i = 0; i <= BytesRead; i++) Buf2[i] = Buf1[i];
  free(Buf1);

  return(Buf2);
  }




void ShowErrorMessage(struct TokenStruct *Token, int Result) {
  int Symbol;
  int i;
  wchar_t s1[BUFSIZ];

  switch(Result) {
    case PARSELEXICALERROR:
      fprintf(stdout,"Lexical error");
      break;
    case PARSECOMMENTERROR:
      fprintf(stdout,"Comment error");
      break;
    case PARSETOKENERROR:
      fprintf(stdout,"Tokenizer error");
      break;
    case PARSESYNTAXERROR:
      fprintf(stdout,"Syntax error");
      break;
    case PARSEMEMORYERROR:
      fprintf(stdout,"Out of memory");
      break;
    }
  if (Token != NULL) fprintf(stdout," at line %ld column %ld",Token->Line,Token->Column);
  fprintf(stdout,".\n");

  if (Result == PARSELEXICALERROR) {
    if (Token->Data != NULL) {
        ReadableString(Token->Data,s1,BUFSIZ);
        fprintf(stdout,"The grammar does not specify what to do with '%S'.\n",s1);
      } else {
        fprintf(stdout,"The grammar does not specify what to do.\n");
        }
    }
  if (Result == PARSETOKENERROR) {
    fprintf(stdout,"The tokenizer returned a non-terminal.\n");
    }
  if (Result == PARSECOMMENTERROR) {
    fprintf(stdout,"The comment has no end, it was started but not finished.\n");
    }
  if (Result == PARSESYNTAXERROR) {
    if (Token->Data != NULL) {
        ReadableString(Token->Data,s1,BUFSIZ);
        fprintf(stdout,"Encountered '%S', but expected ",s1);
      } else {
        fprintf(stdout,"Expected ");
        }
    for (i = 0; i < Grammar.LalrArray[Token->Symbol].ActionCount; i++) {
      Symbol = Grammar.LalrArray[Token->Symbol].Actions[i].Entry;
      if (Grammar.SymbolArray[Symbol].Kind == SYMBOLTERMINAL) {
        if (i > 0) {
          fprintf(stdout,", ");
          if (i >= Grammar.LalrArray[Token->Symbol].ActionCount - 2) fprintf(stdout,"or ");
          }
        fprintf(stdout,"'%S'",Grammar.SymbolArray[Symbol].Name);
        }
      }
    fprintf(stdout,".\n");
    }
  }
